{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture cap\n",
    "# see MTD with QE: https://www.quantum-espresso.org/wp-content/uploads/2022/03/plumed_quick_ref.pdf\n",
    "# \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = \"6,1\"\n",
    "os.environ[\"ASE_DFTB_COMMAND\"] = \"ulimit -s unlimited; /home/dlb/anaconda3/envs/dftb_plumed/bin/dftb+ > PREFIX.out\"\n",
    "os.environ[\"DFTB_PREFIX\"] = \"/home/dlb/Downloads/pbc-0-3\"\n",
    "\n",
    "# https://www.plumed.org/doc-v2.7/user-doc/html/_m_e_t_a_d.html\n",
    "# https://github.com/dftbplus/dftbplus/issues/1064\n",
    "# try with numpy 1.22ã€€\n",
    "# https://gitlab.com/Sucerquia/ase-plumed_tutorial\n",
    "\n",
    "from ase.calculators.lj import LennardJones\n",
    "# from ase.calculators.plumed import Plumed\n",
    "from runner.plumed import Plumed\n",
    "# from plumed import Plumed\n",
    "from ase.constraints import FixedPlane\n",
    "from ase.io import read\n",
    "from ase import units\n",
    "\n",
    "from ase.geometry.analysis import Analysis\n",
    "from ase.constraints import FixAtoms, FixBondLengths\n",
    "\n",
    "# import plumed\n",
    "\n",
    "from ase.calculators.dftb import Dftb\n",
    "\n",
    "\n",
    "\n",
    "ps = 1000 * units.fs\n",
    "\n",
    "setup = [f\"UNITS LENGTH=A TIME={1/ps} ENERGY={units.mol/units.kJ}\",\n",
    "        #  \"d: DISTANCE ATOMS=1,2 \",\n",
    "        \"at8: FIXEDATOM AT=-0.3652684296711638,5.59639757164289,11.089411052917308\",\n",
    "        \"at6: FIXEDATOM AT=-0.5388786945959876,6.471914514609469,10.07028636148657\",\n",
    "        \"c1: CENTER ATOMS=at8,at6\",\n",
    "        \"c2: CENTER ATOMS=67,69,73,77,79,83\",\n",
    "        \"c3: CENTER ATOMS=7,9,11,13,15,17\",\n",
    "        \"c4: CENTER ATOMS=79,83\",\n",
    "         \"phi: TORSION ATOMS=c1,c2,c3,c4\",\n",
    "         \"metad: METAD ARG=phi SIGMA=1.10 HEIGHT=15.0 BIASFACTOR=5 TEMP=300.0 PACE=1\", #GRID_MIN=-pi GRID_MAX=pi GRID_BIN=1500\n",
    "         # \"ARG=d SIGMA=0.20,0.20 HEIGHT=1.20 BIASFACTOR=5 TEMP=300.0 PACE=500\",\n",
    "         # \"GRID_MIN=0,0 GRID_MAX=1.0,1.0 GRID_BIN=150,150\",\n",
    "         \"PRINT ARG=phi STRIDE=1 FILE=../results/test/plumed/COLVAR\",\n",
    "         # \"CALC_RCT \",\n",
    "         # \"RCT_USTRIDE=10\",\n",
    "         # \"...\",\n",
    "         \"FLUSH STRIDE=1000\"]\n",
    "\n",
    "\n",
    "atoms = read('../data/structures/new_systems/ktu_002.cif')\n",
    "\n",
    "\n",
    "# fix_atoms = FixAtoms(indices=[atom.index for atom in atoms if atom.symbol=='N' or atom.symbol=='Si' or atom.symbol=='O'])\n",
    "# # # ch_bonds = Analysis(atoms).get_bonds(\"C\", \"H\")[0]\n",
    "# # # fix_bond_lengths = FixBondLengths(ch_bonds)\n",
    "# # # atoms.set_constraint([fix_atoms, fix_bond_lengths])\n",
    "# atoms.set_constraint(fix_atoms)\n",
    "\n",
    "calc_base = Dftb(atoms=atoms,\n",
    "            label='crystal',\n",
    "            kpts=(1,1,1)\n",
    "            )\n",
    "\n",
    "# atoms.calc = Plumed(calc=calc_base,\n",
    "#                     input=setup,\n",
    "#                     timestep=timestep,\n",
    "#                     atoms=atoms,\n",
    "#                     kT=0.1,\n",
    "#                     log='../results/test/plumed/plumed_log.log')\n",
    "\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "from ase.md.langevin import Langevin\n",
    "\n",
    "atoms.calc = calc_base\n",
    "\n",
    "# dyn = Langevin(atoms, 0.1, temperature_K=0.1/units.kB, friction=0.1,\n",
    "#                fixcm=True, trajectory='../results/test/machine_learning/dftb_500.xyz')\n",
    "# We want to run MD with constant energy using the VelocityVerlet algorithm.\n",
    "dyn = VelocityVerlet(atoms, dt=0.5*units.fs, trajectory='../results/test/machine_learning/dftb_500.traj')  \n",
    "# https://wiki.fysik.dtu.dk/ase/ase/md.html\n",
    "\n",
    "dyn.run(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read, write\n",
    "from ase.visualize import view\n",
    "\n",
    "traj = read('../results/test/machine_learning/dftb_500.traj', index=\":\")\n",
    "# traj = read('/home/dlb/Downloads/UnbiasMD.xyz', index=\":\")\n",
    "# write(\"test/plumed/biased_MTD.xyz\", traj, format=\"extxyz\")\n",
    "# traj_biased = read('test/plumed/biased_MTD.xyz', index=\":\")\n",
    "# traj_unbiased = read('test/plumed/.xyz', index=\":\")\n",
    "\n",
    "view(traj)\n",
    "# print(traj[200].get_potential_energy())\n",
    "# print(traj[200].get_forces()[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if correct forces were written into traj file\n",
    "# https://github.com/qsnake/ase/blob/master/ase/calculators/singlepoint.py\n",
    "# atoms = read('../data/structures/new_systems/ktu_002.cif')\n",
    "\n",
    "from ase.calculators.singlepoint import SinglePointCalculator\n",
    "\n",
    "snap = traj[200].copy()\n",
    "\n",
    "calc_base = Dftb(atoms=atoms,\n",
    "            label='crystal',\n",
    "            kpts=(1,1,1)\n",
    "            )\n",
    "\n",
    "snap.calc = calc_base\n",
    "\n",
    "print(snap.get_potential_energy())\n",
    "print(snap.get_forces()[33])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "from ase import io\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "traj_md = io.read(\"../results/test/machine_learning/dftb_500.traj\", index=\":\")\n",
    "energies_md = np.zeros(len(traj_md) )\n",
    "forces_md = np.zeros( (len(traj_md), len(traj_md[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_md):\n",
    "    energies_md[i] = snap.get_potential_energy()\n",
    "    forces_md[i] = snap.get_forces()\n",
    "# forces_md = np.load(\"../../data/xtb_md/forces_xtb_md.npy\")\n",
    "# energies_md = np.load(\"../../data/xtb_md/energies_xtb_md.npy\")\n",
    "\n",
    "# Training data:\n",
    "# training_indices = np.sort(  np.random.choice(np.arange(200,220), 3, replace=False) )\n",
    "training_indices = np.sort(  np.arange(200, 300, 5) )  \n",
    "traj_train = [traj_md[i] for i in training_indices]\n",
    "energies_train = energies_md[training_indices]\n",
    "forces_train = forces_md[training_indices]\n",
    "train_data = {'trajectory': traj_train, 'energies': energies_train, 'forces': forces_train}\n",
    "\n",
    "#Test data:\n",
    "# test_indices = np.sort(  np.random.choice(np.arange(0,92795), 200, replace=False) ) \n",
    "test_indices = np.sort(  np.arange(200,220,1) ) \n",
    "traj_test = [traj_md[i] for i in test_indices]\n",
    "energies_test = energies_md[test_indices]\n",
    "forces_test = forces_md[test_indices]\n",
    "test_data = {'trajectory': traj_test, 'energies': energies_test, 'forces': forces_test}\n",
    "\n",
    "data_units = \"ev_angstrom\" # standard ase units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using with fande environment\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../fande\") # Adds higher directory to python modules path.\n",
    "# sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "hparams = {\n",
    "    'dtype' : 'float64',\n",
    "    'device' : 'gpu'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(fdm.forces_train_norm.shape)\n",
    "# plt.plot(fdm.forces_train[:,49,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "\n",
    "b = np.array([2,2,4,4])\n",
    "\n",
    "a==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from fande.data import FandeDataModuleASE\n",
    "\n",
    "# train_centers_positions = [43,49,73,79,29,35,  53,59,69,83,25,39,  75,81,31,37,45,51]\n",
    "# train_derivatives_positions = [43,49,73,79,29,35,  53,59,69,83,25,39,  75,81,31,37,45,51]\n",
    "\n",
    "train_centers_positions = list(range(264))\n",
    "train_derivatives_positions = list(range(264))\n",
    "# train_derivatives_positions = [25,39,53,59,69,83]\n",
    "# train_centers_positions = [43\n",
    "# train_derivatives_positions = [\n",
    "\n",
    "# train_derivatives_positions = [29, 35, 43, 49, 73, 79]\n",
    "# train_centers_positions = [6, 10, 14,   7, 11, 15]\n",
    "# train_derivatives_positions = [28, 34, 72, 78, 42, 48,   29, 35, 43, 49, 73, 79]\n",
    "\n",
    "test_centers_positions = [0]\n",
    "test_derivatives_positions = [0]\n",
    "# centers_positions = None\n",
    "# derivatives_positions = None\n",
    "\n",
    "# Descriptors parameters:\n",
    "soap_params = {\n",
    "    'species': [\"H\", \"C\"],\n",
    "    'periodic': True,\n",
    "    'rcut': 5.0,\n",
    "    'sigma': 0.5,\n",
    "    'nmax': 5,\n",
    "    'lmax': 5,\n",
    "    'average': \"off\",\n",
    "    'crossover': True,\n",
    "    'dtype': \"float64\",\n",
    "    'n_jobs': 10,\n",
    "    'sparse': False,\n",
    "    'positions': [7, 11, 15] # ignored\n",
    "}\n",
    "\n",
    "fdm = FandeDataModuleASE(train_data, test_data, hparams, units=data_units)\n",
    "\n",
    "train_gi, test_gi = fdm.calculate_invariants_librascal(\n",
    "    soap_params, \n",
    "    train_centers_positions, \n",
    "    train_derivatives_positions,\n",
    "    test_centers_positions, \n",
    "    test_derivatives_positions,\n",
    "    same_centers_derivatives=True)\n",
    "\n",
    "\n",
    "print(fdm.train_DX.shape)\n",
    "print(fdm.test_DX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = traj_md[100].get_forces().flatten()\n",
    "# ff.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.linalg.norm(fdm.train_DX[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fdm.train_F[1::1], linestyle = 'None', marker='o')\n",
    "plt.plot(fdm.test_F[1::1], linestyle = 'None', marker='o')\n",
    "\n",
    "print(fdm.train_DX.shape, fdm.train_F.shape )\n",
    "print(fdm.test_DX.shape, fdm.test_F.shape )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "from fande.models import ModelForces, ModelEnergies, MyCallbacks\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import numpy as np\n",
    "# seed_everything(42, workers=True)\n",
    "\n",
    "train_DX = fdm.train_DX\n",
    "train_F = fdm.train_F\n",
    "test_DX = fdm.test_DX\n",
    "test_F = fdm.test_F\n",
    "\n",
    "training_random_samples = 4000#train_F.shape[0]\n",
    "num_epochs = 600\n",
    "learning_rate = 0.01\n",
    "\n",
    "# ind_slice = np.sort( np.concatenate( \n",
    "#     ( np.arange(0,4800), np.arange(11*4800,12*4800), np.random.choice(np.arange(4800,59200), 300, replace=False) ) \n",
    "#     ) )\n",
    "\n",
    "ind_slice = np.sort(  np.random.choice(np.arange(0,train_F.shape[0]), training_random_samples, replace=False) ) \n",
    "# ind_slice = np.sort(  np.arange(0,2550) ) \n",
    "# ind_slice = np.sort(  np.arange(0,train_F.shape[0]) ) \n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_DX[ind_slice], train_F[ind_slice])\n",
    "train_loader = DataLoader(train_dataset, batch_size=100_000)\n",
    "\n",
    "model_f = ModelForces(train_DX[ind_slice], train_F[ind_slice], hparams, learning_rate)\n",
    "\n",
    "trainer_f = Trainer(\n",
    "    gpus=1, \n",
    "    max_epochs=num_epochs, \n",
    "    precision=32,\n",
    "    weights_summary='full', \n",
    "    callbacks=[MyCallbacks()])\n",
    "\n",
    "trainer_f.fit(model_f, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = get_optimal_radial_basis_hypers(hypers, frames, expanded_max_radial=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fande.predict import PredictorASE\n",
    "\n",
    "model_e = None\n",
    "trainer_e = None\n",
    "\n",
    "predictor = PredictorASE(\n",
    "            fdm,\n",
    "            model_e,\n",
    "            model_f,\n",
    "            trainer_e,\n",
    "            trainer_f,\n",
    "            hparams,\n",
    "            soap_params\n",
    ")\n",
    "\n",
    "test_centers_positions = list(range(264))\n",
    "test_derivatives_positions = list(range(264))\n",
    "\n",
    "test_gi = fdm.calculate_test_invariants_librascal(\n",
    "    test_centers_positions, \n",
    "    test_derivatives_positions,\n",
    "    same_centers_derivatives=True)\n",
    "\n",
    "errors = predictor.test_errors(plot=True)\n",
    "\n",
    "\n",
    "print(\"MSE: \", np.mean(errors**2) )\n",
    "print(\"MAE: \", np.mean( abs(errors)) )\n",
    "print(\"Max error: \", max(abs(errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_gi.shape, errors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the indices of max erorrs\n",
    "\n",
    "abs_errors = abs(errors)\n",
    "ind_max = np.argpartition(abs_errors, -10)[-10:]\n",
    "print(abs_errors[ind_max])\n",
    "\n",
    "ind_max = ind_max%test_gi.shape[0]\n",
    "print(test_gi[ind_max]%264)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All 15_000 samples CG ERRORS:\n",
    "MSE:  1.1444722\n",
    "MAE:  0.85808694\n",
    "Max error:  4.1879587\n",
    "\n",
    "10_000 samples:\n",
    "MSE:  0.075882606\n",
    "MAE:  0.2096666\n",
    "Max error:  2.990028\n",
    "\n",
    "6000 samples:\n",
    "MSE:  0.06504093\n",
    "MAE:  0.15767942\n",
    "Max error:  4.1622434\n",
    "\n",
    "5000 samples:\n",
    "MSE:  0.056790385\n",
    "MAE:  0.1495894\n",
    "Max error:  2.7035623\n",
    "\n",
    "4000 samples:\n",
    "MSE:  0.109407514\n",
    "MAE:  0.18077059\n",
    "Max error:  5.444092\n",
    "\n",
    "3000 samples:\n",
    "MSE:  0.13578652\n",
    "MAE:  0.21768376\n",
    "Max error:  4.5557604\n",
    "\n",
    "\n",
    "2000 samples:\n",
    "MSE:  0.19382845\n",
    "MAE:  0.26960444\n",
    "Max error:  3.7858768\n",
    "\n",
    "\n",
    "1000 samples:\n",
    "MSE:  0.3523444\n",
    "MAE:  0.38389957\n",
    "Max error:  6.225298\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_centers_positions = [162]\n",
    "test_derivatives_positions = [162]\n",
    "\n",
    "test_gi = fdm.calculate_test_invariants_librascal(\n",
    "    test_centers_positions, \n",
    "    test_derivatives_positions,\n",
    "    same_centers_derivatives=True)\n",
    "\n",
    "# del predictor\n",
    "\n",
    "predictor.predict_and_plot_forces_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "\n",
    "view(traj_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "snapshot = traj_md[0]\n",
    "\n",
    "# for i in range(5):\n",
    "#     fdm.calculate_snapshot_invariants_librascal(snapshot)\n",
    "\n",
    "# fdm.snap_DX.shape\n",
    "s=0\n",
    "for i in range(4):\n",
    "    snapshot = traj_md[i]\n",
    "    try:\n",
    "        predictor.predict_forces_single_snapshot_r(snapshot)\n",
    "    except:\n",
    "        s = s+1\n",
    "        print(\"\\n You are a failure!!! Emotional daaaamage!!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.get_pbc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MD with fande calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture c\n",
    "from fande.ase import FandeCalc\n",
    "from runner.dynamics import MDRunner\n",
    "\n",
    "from ase import units\n",
    "\n",
    "import logging\n",
    "\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR) # logging.ERROR to disable or INFO\n",
    "\n",
    "# atoms = fdm.mol_traj[10].copy()\n",
    "atoms = traj_md[100].copy()\n",
    "atoms.set_pbc(True)\n",
    "\n",
    "atoms.calc = FandeCalc(predictor)\n",
    "\n",
    "# print( atoms.get_forces() )\n",
    "# print( atoms.get_potential_energy())\n",
    "# \"../results/test/\"\n",
    "# mdr = MDRunner(atoms, \"../results/test/md_runs/md_test.traj\", \"../results/test/md_runs/md_log.log\")\n",
    "# mdr.run(dt=0.5*units.fs, num_steps=200)\n",
    "\n",
    "# MaxwellBoltzmannDistribution(self.atoms, temperature_K=300)\n",
    "\n",
    "dyn = VelocityVerlet(\n",
    "    atoms,\n",
    "    dt = 0.4*units.fs,\n",
    "    trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "    logfile=\"../results/test/md_runs/md_log.log\",\n",
    ")\n",
    "\n",
    "dyn.run(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../results/test/md_runs/captured_output.log\", \"w\")\n",
    "a = file.write(c.stdout)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "from ase.io import read\n",
    "\n",
    "traj = read(\"../results/test/md_runs/md_test.traj\", index=\":\")\n",
    "\n",
    "view(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipyparallel as ipp\n",
    "\n",
    "cluster = ipp.Cluster(n=4)\n",
    "with cluster as rc:\n",
    "    ar = rc[:].apply_async(os.getpid)\n",
    "    pid_map = ar.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Cluster(n=4).start_and_connect_sync()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
